{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05f6ffb",
   "metadata": {},
   "source": [
    "## 1. Why was Machine Learning Introduced?\n",
    "Ans:  \n",
    "\n",
    "The simplest answer is to make our lives easier. In the early days of “intelligent” applications, many systems used hardcoded rules of “if” and “else” decisions to process data or adjust the user input. Think of a spam filter whose job is to move the appropriate incoming email messages to a spam folder.  \n",
    "\n",
    "But with the machine learning algorithms, we are given ample information for the data to learn and identify the patterns from the data.\n",
    "\n",
    "Unlike the normal problems we don’t need to write the new rules for each problem in machine learning, we just need to use the same workflow but with a different dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9abb7",
   "metadata": {},
   "source": [
    "## 2. What is Supervised Learning?\n",
    "Sol: \n",
    "\n",
    "\n",
    "Supervised learning is a machine learning algorithm of inferring a function from labeled training data. The training data consists of a set of training examples.\n",
    "\n",
    "Example: 01\n",
    "\n",
    "Knowing the height and weight identifying the gender of the person. Below are the popular supervised learning algorithms. \n",
    "\n",
    "Support Vector Machines\n",
    "\n",
    "Regression\n",
    "\n",
    "Naive Bayes\n",
    "\n",
    "Decision Trees\n",
    "\n",
    "K-nearest Neighbour Algorithm and Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90041da8",
   "metadata": {},
   "source": [
    "## 3. What is Unsupervised Learning?\n",
    "Unsupervised learning is also a type of machine learning algorithm used to find patterns on the set of data given. In this, we don’t have any dependent variable or label to predict. Unsupervised Learning Algorithms:\n",
    "\n",
    "Clustering,\n",
    "\n",
    "Anomaly Detection, \n",
    "\n",
    "Neural Networks and Latent Variable Models.\n",
    "Example:\n",
    "\n",
    "In the same example, a T-shirt clustering will categorize as “collar style and V neck style”, “crew neck style” and “sleeve types”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d240b",
   "metadata": {},
   "source": [
    "## 4. What is ‘Naive’ in a Naive Bayes?\n",
    "Sol: \n",
    "The Naive Bayes method is a supervised learning algorithm, it is naive since it makes assumptions by applying Bayes’ theorem that all attributes are independent of each other.\n",
    "\n",
    "Bayes’ theorem states the following relationship, given class variable y and dependent vector x1  through xn:\n",
    "\n",
    "P(yi | x1,..., xn) =P(yi)P(x1,..., xn | yi)(P(x1,..., xn)\n",
    "\n",
    "Using the naive conditional independence assumption that each xiis independent: for all I this relationship is simplified to:\n",
    "\n",
    "P(xi | yi, x1, ..., xi-1, xi+1, ...., xn) = P(xi | yi)\n",
    "\n",
    "Since, P(x1,..., xn) is a constant given the input, we can use the following classification rule:\n",
    "\n",
    "P(yi | x1, ..., xn) = P(y) ni=1P(xi | yi)P(x1,...,xn) and we can also use Maximum A Posteriori (MAP) estimation to estimate P(yi)and P(yi | xi) the former is then the relative frequency of class yin the training set.\n",
    "\n",
    "P(yi | x1,..., xn)  P(yi) ni=1P(xi | yi)\n",
    "\n",
    "y = arg max P(yi)ni=1P(xi | yi)\n",
    "\n",
    "The different naive Bayes classifiers mainly differ by the assumptions they make regarding the distribution of P(yi | xi): can be Bernoulli, binomial, Gaussian, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ede2d8",
   "metadata": {},
   "source": [
    "## 5. What is PCA? When do you use it?\n",
    "Sol:\n",
    "\n",
    "Principal component analysis (PCA) is most commonly used for dimension reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da74efd",
   "metadata": {},
   "source": [
    "## 6. Explain SVM Algorithm in Detail\n",
    "A Support Vector Machine (SVM) is a very powerful and versatile supervised machine learning model, capable of performing linear or non-linear classification, regression, and even outlier detection.\n",
    "\n",
    "Suppose we have given some data points that each belong to one of two classes, and the goal is to separate two classes based on a set of examples.\n",
    "\n",
    "In SVM, a data point is viewed as a p-dimensional vector (a list of p numbers), and we wanted to know whether we can separate such points with a (p-1)-dimensional hyperplane. This is called a linear classifier.\n",
    "\n",
    "There are many hyperplanes that classify the data. To choose the best hyperplane that represents the largest separation or margin between the two classes. \n",
    "If such a hyperplane exists, it is known as a maximum-margin hyperplane and the linear classifier it defines is known as a maximum margin classifier. The best hyperplane that divides the data in H3\n",
    "\n",
    "We have data (x1, y1), ..., (xn, yn), and different features (xii, ..., xip), and yiis either 1 or -1.\n",
    "\n",
    "The equation of the hyperplane H3 is the set of points satisfying:\n",
    "\n",
    "w. x-b = 0\n",
    "\n",
    "Where w is the normal vector of the hyperplane. The parameter b||w||determines the offset of the hyperplane from the original along the normal vector w\n",
    "\n",
    "So for each i, either xiis in the hyperplane of 1 or -1. Basically, xisatisfies:\n",
    "\n",
    "w . xi - b = 1  or   w. xi - b = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ea790",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52185e1",
   "metadata": {},
   "source": [
    "## 7. What are Support Vectors in SVM?\n",
    "Sol: \n",
    "A Support Vector Machine (SVM) is an algorithm that tries to fit a line (or plane or hyperplane) between the different classes that maximizes the distance from the line to the points of the classes.\n",
    "\n",
    "In this way, it tries to find a robust separation between the classes. The Support Vectors are the points of the edge of the dividing hyperplane as in the below figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e45052",
   "metadata": {},
   "source": [
    "## 8. What are Support Vectors in SVM?\n",
    "Sol: \n",
    "A Support Vector Machine (SVM) is an algorithm that tries to fit a line (or plane or hyperplane) between the different classes that maximizes the distance from the line to the points of the classes.\n",
    "\n",
    "In this way, it tries to find a robust separation between the classes. The Support Vectors are the points of the edge of the dividing hyperplane as in the below figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7115c8c",
   "metadata": {},
   "source": [
    "## 9. What is Cross-Validation?\n",
    "Sol;\n",
    "\n",
    "Cross-validation is a method of splitting all your data into three parts: training, testing, and validation data. Data is split into k subsets, and the model has trained on k-1of those datasets.\n",
    "\n",
    "The last subset is held for testing. This is done for each of the subsets. This is k-fold cross-validation. Finally, the scores from all the k-folds are averaged to produce the final score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12667d8",
   "metadata": {},
   "source": [
    "## 10. What is Bias in Machine Learning?\n",
    "Sol: \n",
    "Bias in data tells us there is inconsistency in data. The inconsistency may occur for several reasons which are not mutually exclusive.\n",
    "\n",
    "For example, a tech giant like Amazon to speed the hiring process they build one engine where they are going to give 100 resumes, it will spit out the top five, and hire those.\n",
    "\n",
    "When the company realized the software was not producing gender-neutral results it was tweaked to remove this bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b64f34",
   "metadata": {},
   "source": [
    "## 11. Explain the Difference Between Classification and Regression?\n",
    "Sol: \n",
    "\n",
    "Classification is used to produce discrete results, classification is used to classify data into some specific categories.\n",
    "For example, classifying emails into spam and non-spam categories. \n",
    "\n",
    "Whereas, regression deals with continuous data.\n",
    "For example, predicting stock prices at a certain point in time.\n",
    "\n",
    "Classification is used to predict the output into a group of classes. \n",
    "For example, Is it Hot or Cold tomorrow?\n",
    "\n",
    "Whereas, regression is used to predict the relationship that data represents. \n",
    "For example, What is the temperature tomorrow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44ee15",
   "metadata": {},
   "source": [
    "## 13. What is F1 score? How would you use it?\n",
    "Sol:\n",
    "    In binary classification we consider the F1 score to be a measure of the model’s accuracy. The F1 score is a weighted average of precision and recall scores.\n",
    "\n",
    "F1 = 2TP/2TP + FP + FN\n",
    "\n",
    "We see scores for F1 between 0 and 1, where 0 is the worst score and 1 is the best score. \n",
    "The F1 score is typically used in information retrieval to see how well a model retrieves relevant results and our model is performing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e45d7b",
   "metadata": {},
   "source": [
    "## 14. Define Precision and Recall?\n",
    "Precision and recall are ways of monitoring the power of machine learning implementation. But they often used at the same time.\n",
    "\n",
    "Precision answers the question, “Out of the items that the classifier predicted to be relevant, how many are truly relevant?”\n",
    "\n",
    "Whereas, recall answers the question, “Out of all the items that are truly relevant, how many are found by the classifier?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccc0348",
   "metadata": {},
   "source": [
    "## 15. How to Tackle Overfitting and Underfitting?\n",
    "Overfitting means the model fitted to training data too well, in this case, we need to resample the data and estimate the model accuracy using techniques like k-fold cross-validation.\n",
    "\n",
    "Whereas for the Underfitting case we are not able to understand or capture the patterns from the data, in this case, we need to change the algorithms, or we need to feed more data points to the model.\n",
    "\n",
    "## 16. What is a Neural Network?\n",
    "\n",
    "It is a simplified model of the human brain. Much like the brain, it has neurons that activate when encountering something similar.\n",
    "\n",
    "The different neurons are connected via connections that help information flow from one neuron to another.\n",
    "\n",
    "## 17. What are Loss Function and Cost Functions? Explain the key Difference Between them?\n",
    "When calculating loss we consider only a single data point, then we use the term loss function.\n",
    "\n",
    "Whereas, when calculating the sum of error for multiple data then we use the cost function. There is no major difference.\n",
    "\n",
    "In other words, the loss function is to capture the difference between the actual and predicted values for a single record whereas cost functions aggregate the difference for the entire training dataset.\n",
    "\n",
    "The Most commonly used loss functions are Mean-squared error and Hinge loss.\n",
    "\n",
    "Mean-Squared Error(MSE): In simple words, we can say how our model predicted values against the actual values.\n",
    "\n",
    "MSE = √(predicted value - actual value)2\n",
    "Hinge loss: It is used to train the machine learning classifier, which is\n",
    "\n",
    "L(y) = max(0,1- yy)\n",
    "\n",
    "Where y = -1 or 1 indicating two classes and y represents the output form of the classifier. The most common cost function represents the total cost as the sum of the fixed costs and the variable costs in the equation y = mx + b\n",
    "\n",
    "## 18. What is Ensemble learning?\n",
    "Ensemble learning is a method that combines multiple machine learning models to create more powerful models.\n",
    "\n",
    "There are many reasons for a model to be different. Few reasons are:\n",
    "\n",
    "Different Population\n",
    "\n",
    "Different Hypothesis\n",
    "\n",
    "Different modeling techniques\n",
    "\n",
    "When working with the model’s training and testing data, we will experience an error. This error might be bias, variance, and irreducible error.\n",
    "\n",
    "Now the model should always have a balance between bias and variance, which we call a bias-variance trade-off.\n",
    "\n",
    "This ensemble learning is a way to perform this trade-off.\n",
    "\n",
    "There are many ensemble techniques available but when aggregating multiple models there are two general methods:\n",
    "\n",
    "Bagging, a native method: take the training set and generate new training sets off of it.\n",
    "Boosting, a more elegant method: similar to bagging, boosting is used to optimize the best weighting scheme for a training set.\n",
    "## 19. How do you make sure which Machine Learning Algorithm to use?\n",
    "It completely depends on the dataset we have. If the data is discrete we use SVM. If the dataset is continuous we use linear regression.\n",
    "\n",
    "So there is no specific way that lets us know which ML algorithm to use, it all depends on the exploratory data analysis (EDA).\n",
    "\n",
    "EDA is like “interviewing” the dataset; As part of our interview we do the following:\n",
    "\n",
    "Classify our variables as continuous, categorical, and so forth.\n",
    "\n",
    "Summarize our variables using descriptive statistics. \n",
    "\n",
    "Visualize our variables using charts.\n",
    "\n",
    "Based on the above observations select one best-fit algorithm for a particular dataset.\n",
    "\n",
    "## 20. How to Handle Outlier Values?\n",
    "An Outlier is an observation in the dataset that is far away from other observations in the dataset. Tools used to discover outliers are\n",
    "\n",
    "Box plot\n",
    "\n",
    "Z-score\n",
    "\n",
    "Scatter plot, etc.\n",
    "\n",
    "Typically, we need to follow three simple strategies to handle outliers:\n",
    "\n",
    "We can drop them. \n",
    "\n",
    "We can mark them as outliers and include them as a feature.\n",
    "\n",
    "Likewise, we can transform the feature to reduce the effect of the outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490aefc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
